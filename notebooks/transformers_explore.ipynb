{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:41<00:00, 20.74s/it]\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "model = AutoModelForCausalLM.from_pretrained(\"/scratch/gpfs/vv7118/models/hub/models--meta-llama--Llama-3.2-3B-Instruct/snapshots/0cb88a4f764b7a12671c53f0838cd831a0843b95\", torch_dtype=torch.float16, device_map='cuda')\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"/scratch/gpfs/vv7118/models/hub/models--meta-llama--Llama-3.2-3B-Instruct/snapshots/0cb88a4f764b7a12671c53f0838cd831a0843b95\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../models/llama-3.2-3b-instruct-reinit/tokenizer_config.json',\n",
       " '../models/llama-3.2-3b-instruct-reinit/special_tokens_map.json',\n",
       " '../models/llama-3.2-3b-instruct-reinit/tokenizer.json')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for layer in model.children():\n",
    "   if hasattr(layer, 'reset_parameters'):\n",
    "       layer.reset_parameters()\n",
    "\n",
    "\n",
    "model.save_pretrained('../models/llama-3.2-3b-instruct-reinit/')\n",
    "tokenizer.save_pretrained('../models/llama-3.2-3b-instruct-reinit/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'电脑aptive_authentication tud tud heroes SPECIAL'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(model(tokenizer.encode(\"Hello, how are you?\", return_tensors=\"pt\").to(model.device)).logits.argmax(dim=-1).squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenizer.encode(\"Hello, how are you?\", return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokens = tokenizer.apply_chat_template([{\"role\": \"user\", \"content\": \"Hello, how are you?\"}], return_tensors=\"pt\", add_generation_prompt=True)\n",
    "out = model(tokens, output_logits=True, max_new_tokens=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CausalLMOutputWithPast(loss=None, logits=tensor([[[ 7.0547,  9.0312, 13.3203,  ..., -3.7598, -3.7598, -3.7598],\n",
       "         [18.7344,  7.9648,  9.1562,  ..., -0.3777, -0.3779, -0.3782],\n",
       "         [12.1016,  3.2383,  5.5977,  ...,  0.0937,  0.0933,  0.0927],\n",
       "         ...,\n",
       "         [14.6094,  9.7891,  5.7539,  ...,  1.1064,  1.1064,  1.1055],\n",
       "         [18.6562, 10.2422,  7.2734,  ...,  0.6416,  0.6411,  0.6406],\n",
       "         [15.3125,  6.8867,  8.6016,  ..., -0.0352, -0.0355, -0.0356]]],\n",
       "       dtype=torch.float16, grad_fn=<UnsafeViewBackward0>), past_key_values=DynamicCache(), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|begin_of_text|>Hello, how are you?'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokens[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 15, 256000])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "out.logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 15, 256000])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Question, I are you? I'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(out.logits.argmax(dim=-1).squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "folktexts",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
